{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/harisankar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "import matplotlib as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.6-tf\n",
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"yolo.h5\")\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowdresult.jpg\n"
     ]
    }
   ],
   "source": [
    "file_name = \"crowd.jpg\"\n",
    "out_file_name = file_name.split('.')[0]+\"result.jpg\"\n",
    "print(out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(file_name)\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print(type(img))\n",
    "img_shape = img.shape\n",
    "img_height = img_shape[0]\n",
    "img_width = img_shape[1]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 480\n"
     ]
    }
   ],
   "source": [
    "mid_h = math.ceil(img_height/2)\n",
    "mid_w = math.ceil(img_width/2)\n",
    "print(mid_h,mid_w)\n",
    "offset_h = math.ceil(0.15*img_height)\n",
    "offset_w = math.ceil(0.15*img_width)\n",
    "\n",
    "# print(offset_h,offset_w)\n",
    "\n",
    "p1 = (mid_h+offset_h)/img_height\n",
    "p2 = (mid_w+offset_w)/img_width\n",
    "p3 = (mid_h-offset_h)/img_height\n",
    "p4 = (mid_w-offset_w)/img_width\n",
    "\n",
    "# print(p1,p2)\n",
    "\n",
    "box1 = [0,0,p1,p2]\n",
    "box2 = [0,p3,p1,1]\n",
    "box3 = [p4,0,1,p2]\n",
    "box4 = [p4,p3,1,1]\n",
    "\n",
    "box1 = np.array(box1)\n",
    "box2 = np.array(box2)\n",
    "box3 = np.array(box3)\n",
    "box4 = np.array(box4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 540, 960, 3)\n",
      "(4, 4)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-997ce77ba2e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcropped_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "images.append(img)\n",
    "images = np.array(images)\n",
    "print(images.shape)\n",
    "colors = np.array([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]]) \n",
    "\n",
    "box1 = box1.reshape([4])\n",
    "box2 = box2.reshape([4])\n",
    "box3 = box3.reshape([4])\n",
    "box4 = box4.reshape([4])\n",
    "\n",
    "boxes = []\n",
    "boxes.append(box1)\n",
    "boxes.append(box2)\n",
    "boxes.append(box3)\n",
    "boxes.append(box4)\n",
    "boxes = np.array(boxes)\n",
    "# boxes.reshape([4,4])\n",
    "\n",
    "\n",
    "\n",
    "print(boxes.shape)\n",
    "\n",
    "crop_tensor = tf.image.crop_and_resize(\n",
    "    images, boxes, [0,0,0,0], crop_size=[300,534], method='bilinear', extrapolation_value=0,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "cropped_images = crop_tensor.eval(session=tf.Session())\n",
    "\n",
    "print(res.shape)\n",
    "print(type(res_img))\n",
    "print(res_img.shape)\n",
    "\n",
    "for i in range(4):\n",
    "    result = tf.keras.preprocessing.image.array_to_img(cropped_images[i],data_format=None, scale=True, dtype=None)\n",
    "    name = \"abc\"+str(i)+\".jpg\"\n",
    "    result.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detections = detector.detectObjectsFromImage(input_image=\"crowd.jpg\", output_image_path=\"rescrowd.jpg\", minimum_percentage_probability=30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.521006345748901\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "detections = []\n",
    "for i in range(4):\n",
    "    crop_det = detector.detectObjectsFromImage(input_image=cropped_images[i],input_type=\"array\", output_image_path=\"crop_det\"+str(i)+\".jpg\", minimum_percentage_probability=30)\n",
    "    detections.append(crop_det)\n",
    "\n",
    "tac = time.time()\n",
    "\n",
    "elapsed = tac-tic\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'box_points': [226, 195, 237, 214],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 30.356156826019287},\n",
       "  {'box_points': [93, 199, 102, 219],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 31.45049810409546},\n",
       "  {'box_points': [116, 190, 125, 207],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 32.039058208465576},\n",
       "  {'box_points': [367, 197, 375, 216],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 34.21008288860321},\n",
       "  {'box_points': [96, 203, 104, 223],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 34.703636169433594},\n",
       "  {'box_points': [190, 206, 203, 228],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 36.725980043411255},\n",
       "  {'box_points': [85, 193, 94, 216],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 41.897252202034},\n",
       "  {'box_points': [422, 187, 432, 205],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 43.06211471557617},\n",
       "  {'box_points': [103, 205, 112, 225],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 51.39894485473633},\n",
       "  {'box_points': [453, 176, 460, 196],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 52.520108222961426},\n",
       "  {'box_points': [390, 290, 403, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 52.74990200996399},\n",
       "  {'box_points': [148, 219, 165, 236],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 54.135650396347046},\n",
       "  {'box_points': [450, 198, 459, 218],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 62.4977707862854},\n",
       "  {'box_points': [51, 145, 495, 295],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 78.11803221702576},\n",
       "  {'box_points': [74, 194, 84, 217],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 86.47632002830505},\n",
       "  {'box_points': [283, 279, 300, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 87.05606460571289},\n",
       "  {'box_points': [267, 264, 282, 298],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 87.0833158493042},\n",
       "  {'box_points': [241, 253, 256, 289],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 94.2130982875824},\n",
       "  {'box_points': [373, 262, 390, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 96.6815710067749}],\n",
       " [{'box_points': [40, 176, 50, 198],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 38.49530518054962},\n",
       "  {'box_points': [166, 176, 173, 195],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 42.76455640792847},\n",
       "  {'box_points': [513, 208, 524, 228],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 43.8422292470932},\n",
       "  {'box_points': [331, 241, 341, 258],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 46.21941149234772},\n",
       "  {'box_points': [481, 224, 491, 248],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 46.36675417423248},\n",
       "  {'box_points': [275, 238, 288, 276],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 49.655938148498535},\n",
       "  {'box_points': [80, 197, 88, 216],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 50.1440703868866},\n",
       "  {'box_points': [103, 290, 116, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 50.466835498809814},\n",
       "  {'box_points': [255, 234, 268, 282],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 55.701977014541626},\n",
       "  {'box_points': [162, 198, 171, 218],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 62.15298771858215},\n",
       "  {'box_points': [495, 216, 505, 237],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 67.2063946723938},\n",
       "  {'box_points': [322, 272, 342, 299],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 70.81432342529297},\n",
       "  {'box_points': [245, 218, 255, 241],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 75.66415667533875},\n",
       "  {'box_points': [355, 233, 369, 265],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 75.84301829338074},\n",
       "  {'box_points': [0, 277, 12, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 79.673832654953},\n",
       "  {'box_points': [469, 206, 480, 228],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 80.21326065063477},\n",
       "  {'box_points': [315, 225, 325, 249],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 81.53855800628662},\n",
       "  {'box_points': [4, 153, 534, 284],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 84.36360359191895},\n",
       "  {'box_points': [347, 270, 364, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 89.82576131820679},\n",
       "  {'box_points': [86, 262, 103, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 96.6747522354126}],\n",
       " [{'box_points': [87, 32, 96, 54],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 31.74952268600464},\n",
       "  {'box_points': [347, 284, 366, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 34.04000401496887},\n",
       "  {'box_points': [447, 40, 455, 61],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 39.46620523929596},\n",
       "  {'box_points': [453, 14, 459, 32],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 39.7992730140686},\n",
       "  {'box_points': [149, 57, 165, 74],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 46.05470895767212},\n",
       "  {'box_points': [254, 135, 273, 172],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 54.1207492351532},\n",
       "  {'box_points': [74, 33, 84, 56],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 68.21526885032654},\n",
       "  {'box_points': [424, 143, 446, 193],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 74.9640703201294},\n",
       "  {'box_points': [74, 0, 532, 297],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 79.54844832420349},\n",
       "  {'box_points': [268, 103, 284, 144],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 82.72538781166077},\n",
       "  {'box_points': [339, 137, 356, 188],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 84.93585586547852},\n",
       "  {'box_points': [444, 137, 464, 172],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 85.94494462013245},\n",
       "  {'box_points': [464, 142, 484, 183],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 88.60805630683899},\n",
       "  {'box_points': [242, 92, 256, 128],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 89.30277824401855},\n",
       "  {'box_points': [235, 145, 272, 212],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 90.20639061927795},\n",
       "  {'box_points': [282, 117, 300, 167],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 96.1188793182373},\n",
       "  {'box_points': [386, 130, 404, 176],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 97.22906947135925},\n",
       "  {'box_points': [374, 103, 391, 144],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 97.27440476417542},\n",
       "  {'box_points': [78, 259, 110, 300],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 97.43370413780212}],\n",
       " [{'box_points': [278, 65, 289, 82],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 49.095964431762695},\n",
       "  {'box_points': [481, 61, 492, 88],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 54.47991490364075},\n",
       "  {'box_points': [11, 21, 528, 188],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 62.91295289993286},\n",
       "  {'box_points': [495, 53, 505, 75],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 64.44027423858643},\n",
       "  {'box_points': [255, 78, 267, 126],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 66.70675277709961},\n",
       "  {'box_points': [275, 73, 288, 115],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 74.01227355003357},\n",
       "  {'box_points': [314, 62, 325, 91],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 74.20331239700317},\n",
       "  {'box_points': [355, 71, 368, 102],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 77.50004529953003},\n",
       "  {'box_points': [245, 57, 254, 85],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 80.43926358222961},\n",
       "  {'box_points': [51, 138, 69, 188],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 81.0504138469696},\n",
       "  {'box_points': [323, 110, 342, 142],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 82.74950385093689},\n",
       "  {'box_points': [469, 43, 481, 68],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 84.56774950027466},\n",
       "  {'box_points': [139, 148, 164, 198],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 84.94457602500916},\n",
       "  {'box_points': [157, 138, 176, 172],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 86.20947003364563},\n",
       "  {'box_points': [177, 142, 196, 183],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 90.21857976913452},\n",
       "  {'box_points': [0, 120, 13, 166],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 91.27508997917175},\n",
       "  {'box_points': [432, 187, 466, 246],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 94.25792694091797},\n",
       "  {'box_points': [347, 109, 363, 143],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 97.37043976783752},\n",
       "  {'box_points': [100, 130, 117, 175],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 97.68996834754944},\n",
       "  {'box_points': [87, 103, 103, 145],\n",
       "   'name': 'person',\n",
       "   'percentage_probability': 98.02954196929932}]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
